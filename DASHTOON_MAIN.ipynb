{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import vgg19\n",
    "\n",
    "# Generated image size\n",
    "RESIZE_HEIGHT = 607\n",
    "\n",
    "NUM_ITER = 3000\n",
    "\n",
    "# Weights of the different loss components\n",
    "CONTENT_WEIGHT = 8e-4 # 8e-4\n",
    "STYLE_WEIGHT = 8e-1 # 8e-4\n",
    "\n",
    "# The layer to use for the content loss.\n",
    "CONTENT_LAYER_NAME = \"block5_conv2\" # \"block2_conv2\"\n",
    "\n",
    "# List of layers to use for the style loss.\n",
    "STYLE_LAYER_NAMES = [\n",
    "    \"block1_conv1\",\n",
    "    \"block2_conv1\",\n",
    "    \"block3_conv1\",\n",
    "    \"block4_conv1\",\n",
    "    \"block5_conv1\",\n",
    "]\n",
    "\n",
    "def get_result_image_size(image_path, result_height):\n",
    "    image_width, image_height = keras.preprocessing.image.load_img(image_path).size\n",
    "    result_width = int(image_width * result_height / image_height)\n",
    "    return result_height, result_width\n",
    "\n",
    "def preprocess_image(image_path, target_height, target_width):\n",
    "    img = keras.preprocessing.image.load_img(image_path, target_size = (target_height, target_width))\n",
    "    arr = keras.preprocessing.image.img_to_array(img)\n",
    "    arr = np.expand_dims(arr, axis = 0)\n",
    "    arr = vgg19.preprocess_input(arr)\n",
    "    return tf.convert_to_tensor(arr)\n",
    "\n",
    "def get_model():\n",
    "    # Build a VGG19 model loaded with pre-trained ImageNet weights\n",
    "    model = vgg19.VGG19(weights = 'imagenet', include_top = False)\n",
    "\n",
    "    # Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "    # Set up a model that returns the activation values for every layer in VGG19 (as a dict).\n",
    "    return keras.Model(inputs = model.inputs, outputs = outputs_dict)\n",
    "\n",
    "def get_optimizer():\n",
    "    return keras.optimizers.Adam(\n",
    "        keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate = 8.0, decay_steps = 445, decay_rate = 0.98\n",
    "            # initial_learning_rate = 2.0, decay_steps = 376, decay_rate = 0.98\n",
    "        )\n",
    "    )\n",
    "\n",
    "def compute_loss(feature_extractor, combination_image, content_features, style_features):\n",
    "    combination_features = feature_extractor(combination_image)\n",
    "    loss_content = compute_content_loss(content_features, combination_features)\n",
    "    loss_style = compute_style_loss(style_features, combination_features, combination_image.shape[1] * combination_image.shape[2])\n",
    "\n",
    "    return CONTENT_WEIGHT * loss_content + STYLE_WEIGHT * loss_style\n",
    "\n",
    "# A loss function designed to maintain the 'content' of the original_image in the generated_image\n",
    "def compute_content_loss(content_features, combination_features):\n",
    "    original_image = content_features[CONTENT_LAYER_NAME]\n",
    "    generated_image = combination_features[CONTENT_LAYER_NAME]\n",
    "\n",
    "    return tf.reduce_sum(tf.square(generated_image - original_image)) / 2\n",
    "\n",
    "def compute_style_loss(style_features, combination_features, combination_size):\n",
    "    loss_style = 0\n",
    "\n",
    "    for layer_name in STYLE_LAYER_NAMES:\n",
    "        style_feature = style_features[layer_name][0]\n",
    "        combination_feature = combination_features[layer_name][0]\n",
    "        loss_style += style_loss(style_feature, combination_feature, combination_size) / len(STYLE_LAYER_NAMES)\n",
    "\n",
    "    return loss_style\n",
    "\n",
    "# The \"style loss\" is designed to maintain the style of the reference image in the generated image.\n",
    "# It is based on the gram matrices (which capture style) of feature maps from the style reference image and from the generated image\n",
    "def style_loss(style_features, combination_features, combination_size):\n",
    "    S = gram_matrix(style_features)\n",
    "    C = gram_matrix(combination_features)\n",
    "    channels = style_features.shape[2]\n",
    "    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (combination_size ** 2))\n",
    "\n",
    "def gram_matrix(x):\n",
    "   x = tf.transpose(x, (2, 0, 1))\n",
    "   features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
    "   gram = tf.matmul(features, tf.transpose(features))\n",
    "   return gram\n",
    "\n",
    "def save_result(generated_image, result_height, result_width, name):\n",
    "    img = deprocess_image(generated_image, result_height, result_width)\n",
    "    keras.preprocessing.image.save_img(name, img)\n",
    "\n",
    "# Util function to convert a tensor into a valid image\n",
    "def deprocess_image(tensor, result_height, result_width):\n",
    "    tensor = tensor.numpy()\n",
    "    tensor = tensor.reshape((result_height, result_width, 3))\n",
    "\n",
    "    # Remove zero-center by mean pixel\n",
    "    tensor[:, :, 0] += 103.939\n",
    "    tensor[:, :, 1] += 116.779\n",
    "    tensor[:, :, 2] += 123.680\n",
    "\n",
    "    # 'BGR'->'RGB'\n",
    "    tensor = tensor[:, :, ::-1]\n",
    "    return np.clip(tensor, 0, 255).astype(\"uint8\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Prepare content, stlye images\n",
    "    path = os.path.abspath(os.getcwd())\n",
    "    content_image_path = keras.utils.get_file(path + '\\dataset\\paris.jpg', 'https://i.imgur.com/F28w3Ac.jpg')\n",
    "    style_image_path = keras.utils.get_file(path + '\\dataset\\starry_night.jpg', 'https://i.imgur.com/9ooB60I.jpg')\n",
    "    result_height, result_width = get_result_image_size(content_image_path, RESIZE_HEIGHT)\n",
    "    print(\"result resolution: (%d, %d)\" % (result_height, result_width))\n",
    "\n",
    "    # Preprocessing\n",
    "    content_tensor = preprocess_image(content_image_path, result_height, result_width)\n",
    "    style_tensor = preprocess_image(style_image_path, result_height, result_width)\n",
    "    generated_image = tf.Variable(tf.random.uniform(style_tensor.shape, dtype=tf.dtypes.float32))\n",
    "    # generated_image = tf.Variable(preprocess_image(content_image_path, result_height, result_width))\n",
    "\n",
    "    # Build model\n",
    "    model = get_model()\n",
    "    optimizer = get_optimizer()\n",
    "    print(model.summary())\n",
    "\n",
    "    content_features = model(content_tensor)\n",
    "    style_features = model(style_tensor)\n",
    "\n",
    "    # Optimize result image\n",
    "    for iter in range(NUM_ITER):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = compute_loss(model, generated_image, content_features, style_features)\n",
    "\n",
    "        grads = tape.gradient(loss, generated_image)\n",
    "\n",
    "        print(\"iter: %4d, loss: %8.f\" % (iter, loss))\n",
    "        optimizer.apply_gradients([(grads, generated_image)])\n",
    "\n",
    "        if (iter + 1) % 100 == 0:\n",
    "            name = \"result/generated_at_iteration_%d.png\" % (iter + 1)\n",
    "            save_result(generated_image, result_height, result_width, name)\n",
    "\n",
    "    name = \"result/result_%d_%f_%f.png\" % (NUM_ITER, CONTENT_WEIGHT, STYLE_WEIGHT)\n",
    "    save_result(generated_image, result_height, result_width, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e56fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
